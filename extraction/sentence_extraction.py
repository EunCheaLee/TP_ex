import json
import re
from typing import Dict, List, Tuple
from collections import defaultdict
import pandas as pd


class SentenceExtractor:
    def __init__(self):
        self.sentences_by_word = defaultdict(list)  # ë‹¨ì–´ë³„ ë¬¸ì¥ ì €ì¥

    def fix_spacing_errors(self, text: str) -> str:
        """ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •"""
        # ë‹¨ì¼ ê¸€ì + ê³µë°± + ë‹¨ì¼ ê¸€ì íŒ¨í„´ ìˆ˜ì •
        # "ë“œ ë””ì–´" â†’ "ë“œë””ì–´"
        text = re.sub(r'(\S)\s(\S)(?=\s|$|[,.!?])', r'\1\2', text)

        # ì¤‘ë³µ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)

        # ì‰¼í‘œ/ë§ˆì¹¨í‘œ ì• ê³µë°± ì œê±°
        text = re.sub(r'\s+([,.!?])', r'\1', text)

        return text.strip()

    def clean_sentence(self, sentence: str) -> str:
        """ë¬¸ì¥ ì •ì œ"""
        # ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •
        sentence = self.fix_spacing_errors(sentence)

        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ë¬¸ì¥ë¶€í˜¸ëŠ” ìœ ì§€)
        sentence = re.sub(r'[^\w\s\.\!\?\,]', '', sentence)

        # ìˆ«ì, ì‰¼í‘œ ë“± ì œê±°
        sentence = re.sub(r'[0-9ï¼Œ]', '', sentence)

        return sentence.strip()

    def split_sentences(self, text: str) -> List[str]:
        """ë¬¸ì¥ ë¶„ë¦¬"""
        # ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ë¨¼ì € ìˆ˜ì •
        text = self.fix_spacing_errors(text)

        # ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        sentences = re.split(r'[\.!?]+', text)

        # ì •ì œ ë° í•„í„°ë§
        cleaned = []
        for sent in sentences:
            sent = self.clean_sentence(sent)
            # 10ê¸€ì ì´ìƒ, 100ê¸€ì ì´í•˜ì¸ ë¬¸ì¥ë§Œ
            if 10 <= len(sent) <= 100:
                cleaned.append(sent)

        return cleaned

    def extract_sentences_with_word(self, text: str, target_word: str) -> List[str]:
        """íŠ¹ì • ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì¥ ì¶”ì¶œ"""
        sentences = self.split_sentences(text)

        matching = []
        for sent in sentences:
            if target_word in sent:
                matching.append(sent)

        return matching

    def build_sentence_database(self, fairytales: Dict[str, str], vocabulary_df: pd.DataFrame):
        """ëª¨ë“  ë™í™”ì—ì„œ ê° ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì¥ ì¶”ì¶œ"""
        print("\n" + "=" * 60)
        print("ğŸ“ ë™í™” ì›ë¬¸ì—ì„œ ë¬¸ì¥ ì¶”ì¶œ ì¤‘...")
        print("=" * 60)

        # ëª¨ë“  ì–´íœ˜ ë‹¨ì–´ì— ëŒ€í•´
        total_words = len(vocabulary_df)

        for idx, row in vocabulary_df.iterrows():
            word = row['word']

            if (idx + 1) % 100 == 0:
                print(f"  ì§„í–‰: {idx + 1}/{total_words} ({(idx + 1) / total_words * 100:.1f}%)")

            # ëª¨ë“  ë™í™”ì—ì„œ í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì¥ ì°¾ê¸°
            for title, content in fairytales.items():
                sentences = self.extract_sentences_with_word(content, word)
                self.sentences_by_word[word].extend(sentences)

        # í†µê³„
        words_with_sentences = sum(1 for sentences in self.sentences_by_word.values() if sentences)
        total_sentences = sum(len(sentences) for sentences in self.sentences_by_word.values())

        print(f"\nâœ… ë¬¸ì¥ ì¶”ì¶œ ì™„ë£Œ!")
        print(f"  ğŸ“Š ë¬¸ì¥ì´ ìˆëŠ” ë‹¨ì–´: {words_with_sentences}/{total_words}ê°œ")
        print(f"  ğŸ“ ì´ ì¶”ì¶œëœ ë¬¸ì¥: {total_sentences:,}ê°œ")
        print(f"  ğŸ“ˆ í‰ê·  ë¬¸ì¥/ë‹¨ì–´: {total_sentences / words_with_sentences:.1f}ê°œ\n")

        return self.sentences_by_word

    def create_blank_from_sentence(self, sentence: str, target_word: str) -> Tuple[str, int]:
        """ë¬¸ì¥ì—ì„œ ëª©í‘œ ë‹¨ì–´ë¥¼ ë¹ˆì¹¸ìœ¼ë¡œ ë§Œë“¤ê¸°"""
        # ë‹¨ì–´ì˜ ìœ„ì¹˜ ì°¾ê¸°
        if target_word not in sentence:
            return None, -1

        # ë‹¨ì–´ë¥¼ ___ë¡œ êµì²´
        blank_sentence = sentence.replace(target_word, "___", 1)

        # ë¹ˆì¹¸ ìœ„ì¹˜ ê³„ì‚° (ë‹¨ì–´ ì¸ë±ìŠ¤)
        words = sentence.split()
        blank_position = -1
        for i, word in enumerate(words):
            if target_word in word:
                blank_position = i
                break

        return blank_sentence, blank_position

    def save_to_json(self, filepath: str):
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        data = {word: sentences for word, sentences in self.sentences_by_word.items()}

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"âœ… ë¬¸ì¥ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥: {filepath}\n")


# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("ğŸ”§ ë™í™” ë¬¸ì¥ ì¶”ì¶œ ë° ë„ì–´ì“°ê¸° ìˆ˜ì •")
    print("=" * 60)

    # 1. JSON ë¡œë“œ
    with open('../data/json/cleaned_pdf.json', 'r', encoding='utf-8') as f:
        fairytales = json.load(f)

    print(f"\nâœ“ ë™í™”ì±… {len(fairytales)}ê¶Œ ë¡œë“œ")

    # 2. ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •
    extractor = SentenceExtractor()

    print("\n" + "=" * 60)
    print("ğŸ”§ ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì • ì¤‘...")
    print("=" * 60)

    fixed_fairytales = {}
    for title, content in fairytales.items():
        fixed_content = extractor.fix_spacing_errors(content)
        fixed_fairytales[title] = fixed_content

        # ë³€ê²½ ì‚¬í•­ ì¶œë ¥ (ìƒ˜í”Œ)
        if "ë“œ ë””ì–´" in content or "ì°¸ ë§" in content:
            print(f"\nğŸ“– {title}")
            print(f"  ì›ë³¸: {content[:100]}...")
            print(f"  ìˆ˜ì •: {fixed_content[:100]}...")

    # 3. ìˆ˜ì •ëœ JSON ì €ì¥
    with open('../data/json/fixed_fairytales.json', 'w', encoding='utf-8') as f:
        json.dump(fixed_fairytales, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ë„ì–´ì“°ê¸° ìˆ˜ì • ì™„ë£Œ: fixed_fairytales.json\n")

    # 4. ì–´íœ˜ ë°ì´í„° ë¡œë“œ (ì´ì „ì— ìƒì„±í•œ ê²ƒ)
    try:
        vocab_df = pd.read_csv('../learning/vocabulary_data.csv')
        print(f"âœ“ ì–´íœ˜ ë°ì´í„° ë¡œë“œ: {len(vocab_df)}ê°œ ë‹¨ì–´\n")

        # 5. ë¬¸ì¥ ì¶”ì¶œ
        sentences_db = extractor.build_sentence_database(fixed_fairytales, vocab_df)

        # 6. ì €ì¥
        extractor.save_to_json('sentences_database.json')

        # 7. ìƒ˜í”Œ í™•ì¸
        print("=" * 60)
        print("ğŸ“‹ ìƒ˜í”Œ í™•ì¸")
        print("=" * 60)

        sample_words = list(sentences_db.keys())[:5]
        for word in sample_words:
            sentences = sentences_db[word]
            if sentences:
                print(f"\në‹¨ì–´: '{word}'")
                print(f"  ì¶”ì¶œëœ ë¬¸ì¥ ìˆ˜: {len(sentences)}ê°œ")
                print(f"  ì˜ˆì‹œ: {sentences[0]}")

                # ë¹ˆì¹¸ ë§Œë“¤ê¸° í…ŒìŠ¤íŠ¸
                blank, pos = extractor.create_blank_from_sentence(sentences[0], word)
                if blank:
                    print(f"  ë¹ˆì¹¸ ë¬¸ì¥: {blank}")

    except FileNotFoundError:
        print("âš ï¸  vocabulary_data.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € learn_pipeline.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\n")